#!/usr/bin/env python3
import dataclasses
import typing
import unittest

from bunkai.algorithm.bunkai_sbd.annotator.basic_annotator import BasicRule
from bunkai.algorithm.bunkai_sbd.annotator.constant import LAYER_NAME_FIRST
from bunkai.algorithm.bunkai_sbd.annotator.emoji_annotator import \
    EmojiAnnotator
from bunkai.algorithm.bunkai_sbd.annotator.emotion_expression_annotator import \
    EmotionExpressionAnnotator
from bunkai.algorithm.bunkai_sbd.annotator.facemark_detector import \
    FaceMarkDetector
from bunkai.algorithm.bunkai_sbd.annotator.linebreak_force_annotator import \
    LinebreakForceAnnotator
from bunkai.algorithm.bunkai_sbd.bunkai_sbd import \
    BunkaiSentenceBoundaryDisambiguation
from bunkai.base.annotation import Annotations, SpanAnnotation


@dataclasses.dataclass
class TestInstance(object):
    text: str
    n_sentence: int
    expected_rules: typing.Optional[typing.List[str]] = None


def monkeypatch_function(self, original_text: str, spans: Annotations):
    # tokenizerã‚’æ›´æ–°ã™ã‚‹ã€‚ã™ã§ã«Tokenizeæ¸ˆã¿ã®çµæœã‚’åˆ©ç”¨ã™ã‚‹ã€‚
    # self.linebreak_detector.reset_tokenizer(word_tokenizer_type='pre_tokenize', sentence2tokens=sentence2tokens)
    result: typing.List[int] = []

    new_spans = [s for s in spans.get_final_layer()]
    for predicted_index in result:
        char_index_start = new_spans[predicted_index].start_index
        char_index_end = new_spans[predicted_index].end_index
        ann = SpanAnnotation(
            rule_name='LinebreakExceptionAnnotator',
            start_index=char_index_start,
            end_index=char_index_end,
            split_string_type='linebreak',
            split_string_value=original_text[char_index_start: char_index_end])
        new_spans.append(ann)
    spans.add_annotation_layer(self.rule_name, new_spans)

    return spans


class TestBunkaiSbd(unittest.TestCase):
    def setUp(self) -> None:
        self.test_sentences = [
            TestInstance("ã¾ãšã¯ä¸€æ–‡ç›®(^!^)ã¤ãã«äºŒæ–‡ç›®(^^)ã“ã‚Œã€ãƒ†ã‚¹ãƒˆæ–‡ãªã‚“ã§ã™ã‘ã©(ç¬‘)æœ¬å½“?ã«ã“ã‚“ãªãƒ†ã‚­ã‚¹ãƒˆã§ã„ã„ã®ã‹ãªâ˜†"
                         "10ç§’ã§è€ƒãˆã¦æ›¸ã„ãŸã‚ˆ."
                         "(ã‚»ãƒ«ãƒ•ãƒ‰ãƒªãƒ³ã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã¯ã™ã”ãè‰¯ã‹ã£ãŸã§ã™!ç¨®é¡ã‚‚è±Šå¯Œã€‚)"
                         "ãŠã™ã™ã‚åº¦No.1ã®å’Œå®¤3.5ç•³ã¯ã‚ã‚Šã¾ã™ã€‚"
                         "ãŠã—ã¾ã„â™ª"
                         "èª­ç‚¹ã§æ–‡ã‚’åˆ†å‰²ã™ã‚‹ã¨ã„ã†å ´åˆã‚‚ã‚ã‚Šã¾ã™ã€ã—ã‹ã—ç¾åœ¨ã¯å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€‚"
                         "(^ ^) (^ã€€^) å…ˆæœˆæ³Šã¾ã‚Šã¾ã—ãŸãŒ ã¨ã¦ã‚‚ã‚ˆã‹ã£ãŸã§ã™ã€‚"
                         "(è¿‘æ—¥ä¸­ã«ã¯å†·æˆ¿ã«åˆ‡ã‚Šæ›¿ã‚ã‚‹äºˆå®šã§ã™ã€‚\nã„ã„ã§ã™ã­(æ³£))", 11),
            TestInstance("30ä»£ã®å¤«å©¦2çµ„(ç”·2.å¥³2)ã§ã™ã€‚", 2),
            TestInstance("ã“ã®å€¤æ®µã§ã€ã“ã‚“ãªå¤•é£¯ã„ã„ã®ï¼Ÿ\nã£ã¦ã€ãã‚‰ã„ãŠã„ã—ã‹ã£ãŸï¼", 1),
        ]

    def test_various_inputs(self):
        """Inputã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹ã€‚Bertãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã—ãªã„ã€‚"""
        test_cases = [
            TestInstance("ã“ã‚ŒãŒï¼‘æ–‡ç›®ã§ã™ã€‚ã€‚ã€‚ã€‚ãã—ã¦ã€ã“ã‚ŒãŒï¼’æ–‡ç›®â€¦ï¼“æ–‡ç›®ã€‚", 3,
                         expected_rules=[EmotionExpressionAnnotator.__name__, BasicRule.__name__, LAYER_NAME_FIRST]),
            TestInstance("å®¿ã‚’äºˆç´„ã—ã¾ã—ãŸâ™ª!ã¾ã 2ãƒ¶æœˆã‚‚å…ˆã ã‘ã©ã€‚æ—©ã™ãã‹ãª(ç¬‘)æ¥½ã—ã¿ã§ã™â˜…", 4,
                         expected_rules=[EmotionExpressionAnnotator.__name__, BasicRule.__name__, LAYER_NAME_FIRST]),
            TestInstance("å®¿ã‚’äºˆç´„ã—ã¾ã—ãŸğŸ˜„ã¾ã 2ãƒ¶æœˆã‚‚å…ˆã ã‘ã©ğŸ˜„æ—©ã™ãã‹ãª(ç¬‘)æ¥½ã—ã¿ã§ã™â˜…", 4,
                         expected_rules=[EmotionExpressionAnnotator.__name__, EmojiAnnotator.__name__,
                                         LAYER_NAME_FIRST]),
            TestInstance("å®¿ã‚’äºˆç´„ã—ã¾ã—ãŸğŸ˜„ğŸ˜„ğŸ˜„ã¾ã 2ãƒ¶æœˆã‚‚å…ˆã ã‘ã©ğŸ˜„ğŸ˜„ğŸ˜„æ—©ã™ãã‹ãª(ç¬‘)æ¥½ã—ã¿ã§ã™â˜…", 4,
                         expected_rules=[EmotionExpressionAnnotator.__name__, EmojiAnnotator.__name__,
                                         LAYER_NAME_FIRST]),
            TestInstance("å®¿ã‚’äºˆç´„ã—ã¾ã—ãŸï¼¼(^o^)ï¼ã¾ã 2ãƒ¶æœˆã‚‚å…ˆã ã‘ã©ã€‚æ—©ã™ãã‹ãª(ç¬‘)æ¥½ã—ã¿ã§ã™â˜…", 4,
                         expected_rules=[EmotionExpressionAnnotator.__name__, BasicRule.__name__,
                                         FaceMarkDetector.__name__, LAYER_NAME_FIRST]),
            TestInstance("ã“ã®å€¤æ®µã§ã€ã“ã‚“ãªå¤•é£¯ã„ã„ã®ï¼Ÿ\nã£ã¦ã€ãã‚‰ã„ãŠã„ã—ã‹ã£ãŸï¼", 2,
                         expected_rules=[LAYER_NAME_FIRST, LinebreakForceAnnotator.__name__]),
            TestInstance('ã“ã‚Œã¯å…¥åŠ›ã®å…¥åŠ›ã‚µãƒ³ãƒ—ãƒ«ã§ã™(^o^)çµµæ–‡å­—ã®æ–‡æœ«è¨˜å·ã‚‚èªè­˜ã—ã¾ã™ğŸ˜€å¼•ç”¨æ–‡ã‚‚å¤§ä¸ˆå¤«ï¼Ÿã¨æ€ã„ã¾ã›ã‚“ã‹ï¼Ÿå¼•ç”¨æ–‡ã®éå‰°åˆ†å‰²ã‚’é˜²ã’ã‚‹ã‚“ã§ã™ğŸ‘',
                         4, expected_rules=[BasicRule.__name__,
                                            FaceMarkDetector.__name__,
                                            EmojiAnnotator.__name__,
                                            LAYER_NAME_FIRST]),
            TestInstance('æœ¬å•†å“ã¯ãŠã™ã™ã‚åº¦No.1ã§ã™ã€‚', 1, expected_rules=[LAYER_NAME_FIRST]),
            TestInstance('æœ¬å•†å“ã¯ãŠã™ã™ã‚åº¦No.1ã§ã™ï¼ã¨ã„ã†å£²ã‚Šæ–‡å¥ã®æ–°å•†å“ãŒå‡ºã¦ã„ã‚‹ã€‚ã—ã‹ã—ã€ã“ã®å•†å“ã¯æœ¬å½“ã«ä¿¡ç”¨ã§ãã‚‹ã®ã ã‚ã†ã‹ï¼Ÿç§ã¯ã¨ã¦ã‚‚æ‡ç–‘çš„ã§ã‚ã‚‹ã€‚',
                         3, expected_rules=[BasicRule.__name__, LAYER_NAME_FIRST]),
            TestInstance('æœ¬å•†å“ã¯ãŠã™ã™ã‚åº¦No.', 1, expected_rules=[LAYER_NAME_FIRST]),
        ]
        splitter_obj = BunkaiSentenceBoundaryDisambiguation(path_model=None)
        for test_case in test_cases:
            self.assertEqual(len(list(splitter_obj(test_case.text))), test_case.n_sentence,
                             msg=f'Input={test_case.text} Expect N(sent)={test_case.n_sentence} '
                                 f'Result={list(splitter_obj(test_case.text))}')
            annotations = splitter_obj.eos(test_case.text)
            span_annotations = annotations.get_final_layer()
            self.assertEqual(set([s.rule_name for s in span_annotations]),  # type: ignore
                             set(test_case.expected_rules),  # type: ignore
                             msg=f'text={test_case.text}, '  # type: ignore
                                 f'{set([s.rule_name for s in span_annotations])} '
                                 f'!= {test_case.expected_rules}')


if __name__ == '__main__':
    unittest.main()
